{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ACS Index and Azure SQL Database for Avatar Demo\n",
    "Use this notebook to create an Azure Cognitive Search Index and an Azure SQL Database and populate demo content for the Avatar outdoor shop application.  \n",
    "\n",
    "Ensure that you have the the Microsoft ODBC driver for SQL Server installed. Here are the instructions for Linux based systems:  \n",
    "https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-ver16&tabs=ubuntu18-install%2Calpine17-install%2Cdebian8-install%2Credhat7-13-install%2Crhel7-offline#18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1700038369590
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-search-documents==11.4.0b6 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (11.4.0b6)\n",
      "Requirement already satisfied: openai==0.28.1 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: tenacity in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (8.2.2)\n",
      "Requirement already satisfied: pyodbc in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from azure-search-documents==11.4.0b6) (1.30.2)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from azure-search-documents==11.4.0b6) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from azure-search-documents==11.4.0b6) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from openai==0.28.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from openai==0.28.1) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from openai==0.28.1) (3.9.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0b6) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0b6) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (2024.8.30)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.9.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\chihengchou\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->openai==0.28.1) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the required libraries\n",
    "%pip install azure-search-documents==11.4.0b6 openai==0.28.1 tenacity pyodbc\n",
    "\n",
    "# Install library for Azure Authentication\n",
    "%pip install azure-identity azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "gather": {
     "logged": 1700038372029
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json  \n",
    "import pandas as pd\n",
    "\n",
    "import pyodbc\n",
    "import requests\n",
    "import inspect\n",
    "\n",
    "import openai  \n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import Vector  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    "    SemanticConfiguration,  \n",
    "    PrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    SemanticSettings,  \n",
    "    VectorSearch,  \n",
    "    VectorSearchAlgorithmConfiguration,  \n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "You need to have the following settings for your Azure resources defined in the `local.settings.json` file in the __api__ subfolder to populate the demo content for the outdoor app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chihengchou\\Downloads\\work\\work\\gen-cv-forked\\gen-cv\\avatar\\interactive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\chihengchou\\\\Downloads\\\\work\\\\work\\\\gen-cv-forked\\\\gen-cv\\\\avatar\\\\interactive'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%pwd\n",
    "#!cd c:/users/chihengchou/downloads/work/work/gen-cv-forked/gen-cv/avatar/interactive\n",
    "%cd c:\\\\Users\\\\chihengchou\\\\Downloads\\\\work\\\\work\\\\gen-cv-forked\\\\gen-cv\\\\avatar\\\\interactive\n",
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "gather": {
     "logged": 1700038375485
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load JSON file\n",
    "with open('./api/local.settings.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Azure Cognitive Search\n",
    "service_endpoint = data[\"Values\"][\"AZURE_SEARCH_ENDPOINT\"]\n",
    "key = data[\"Values\"][\"AZURE_SEARCH_API_KEY\"]\n",
    "index_name = data[\"Values\"][\"AZURE_SEARCH_INDEX\"]\n",
    "\n",
    "# Blob SAS URL for Azure Storage Account\n",
    "blob_sas_url = data[\"Values\"][\"BLOB_SAS_URL\"]\n",
    "blob_container_name = data[\"Values\"][\"BLOB_CONTAINER_NAME\"]\n",
    "use_entra_id = data[\"Values\"][\"USE_ENTRA_ID\"]\n",
    "\n",
    "# Azure OpenAI\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = data[\"Values\"][\"AZURE_OPENAI_API_KEY\"]\n",
    "openai.api_base = data[\"Values\"][\"AZURE_OPENAI_ENDPOINT\"]\n",
    "openai.api_version = data[\"Values\"][\"AZURE_OPENAI_API_VERSION\"]\n",
    "AOAI_embeddings_deployment = data[\"Values\"][\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"]\n",
    "\n",
    "# Azure SQL Database\n",
    "sql_db_server = data[\"Values\"][\"SQL_DB_SERVER\"]\n",
    "sql_db_user = data[\"Values\"][\"SQL_DB_USER\"]\n",
    "sql_db_password = data[\"Values\"][\"SQL_DB_PASSWORD\"]\n",
    "sql_db_name = data[\"Values\"][\"SQL_DB_NAME\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Cognitive Search Index\n",
    "First, we create a new Index with demo data to the Cognitive Search service that you have deployed manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "gather": {
     "logged": 1699873170121
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>name</th>\n",
       "      <th>tagline</th>\n",
       "      <th>description</th>\n",
       "      <th>original_price</th>\n",
       "      <th>special_offer</th>\n",
       "      <th>product_image_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1107</td>\n",
       "      <td>tennis</td>\n",
       "      <td>AceMaster 3000</td>\n",
       "      <td>Enhance Your Training with Our High-Precision ...</td>\n",
       "      <td>Introducing the AceMaster 3000, a revolutionar...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>acemaster-3000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1108</td>\n",
       "      <td>tennis</td>\n",
       "      <td>Ace Attire</td>\n",
       "      <td>Exude Style &amp; Comfort with Our Premium Men's T...</td>\n",
       "      <td>Presenting the Ace Attire, a sophisticated men...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>ace-attire.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1109</td>\n",
       "      <td>tennis</td>\n",
       "      <td>Serve &amp; Style</td>\n",
       "      <td>Empower Your Game with Our High-Performance Wo...</td>\n",
       "      <td>Introducing the Serve &amp; Style, an elite women'...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>serve-style.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1110</td>\n",
       "      <td>tennis</td>\n",
       "      <td>Serve &amp; Style</td>\n",
       "      <td>Empower Your Game with Our High-Performance Wo...</td>\n",
       "      <td>The National Development Council proposes five...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>na.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1111</td>\n",
       "      <td>tennis</td>\n",
       "      <td>Serve &amp; Style</td>\n",
       "      <td>Empower Your Game with Our High-Performance Wo...</td>\n",
       "      <td>\"Digital Country. Innovative Economic Developm...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smart-taiwan.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id category            name  \\\n",
       "16  1107   tennis  AceMaster 3000   \n",
       "17  1108   tennis      Ace Attire   \n",
       "18  1109   tennis   Serve & Style   \n",
       "19  1110   tennis   Serve & Style   \n",
       "20  1111   tennis   Serve & Style   \n",
       "\n",
       "                                              tagline  \\\n",
       "16  Enhance Your Training with Our High-Precision ...   \n",
       "17  Exude Style & Comfort with Our Premium Men's T...   \n",
       "18  Empower Your Game with Our High-Performance Wo...   \n",
       "19  Empower Your Game with Our High-Performance Wo...   \n",
       "20  Empower Your Game with Our High-Performance Wo...   \n",
       "\n",
       "                                          description  original_price  \\\n",
       "16  Introducing the AceMaster 3000, a revolutionar...          1000.0   \n",
       "17  Presenting the Ace Attire, a sophisticated men...           120.0   \n",
       "18  Introducing the Serve & Style, an elite women'...           130.0   \n",
       "19  The National Development Council proposes five...             0.0   \n",
       "20  \"Digital Country. Innovative Economic Developm...             0.0   \n",
       "\n",
       "    special_offer  product_image_file  \n",
       "16          950.0  acemaster-3000.png  \n",
       "17          110.0      ace-attire.png  \n",
       "18          115.0     serve-style.png  \n",
       "19            0.0              na.png  \n",
       "20            0.0    smart-taiwan.png  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "credential = AzureKeyCredential(key)\n",
    "\n",
    "# df = pd.read_csv('data/products_cs_index.csv', dtype={'id': str})\n",
    "df = pd.read_csv('data/products_cs_index.csv', encoding='latin1', dtype={'id': str})\n",
    "# display(df.head())\n",
    "display(df.tail())\n",
    "input_data = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "gather": {
     "logged": 1699873170374
    }
   },
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(text):\n",
    "    response = openai.Embedding.create(\n",
    "        input=text, engine=AOAI_embeddings_deployment)\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "gather": {
     "logged": 1699873171802
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Generate embeddings for title and content fields\n",
    "for item in input_data:\n",
    "    tagline = item['tagline']\n",
    "    description = item['description']\n",
    "    tagline_embeddings = generate_embeddings(tagline)\n",
    "    description_embeddings = generate_embeddings(description)\n",
    "    item['tagline_vector'] = tagline_embeddings\n",
    "    item['description_vector'] = description_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "gather": {
     "logged": 1699873171984
    }
   },
   "outputs": [],
   "source": [
    "# Output embeddings to docVectors.json file\n",
    "with open(\"./data/product-catalog-vectors.json\", \"w\") as f:\n",
    "    json.dump(input_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "gather": {
     "logged": 1699873172252
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting existing index...\n"
     ]
    }
   ],
   "source": [
    "# Delete ACS index if it exists\n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)\n",
    "\n",
    "try:\n",
    "    if index_client.get_index(index_name):\n",
    "        print('Deleting existing index...')\n",
    "        index_client.delete_index(index_name)\n",
    "\n",
    "except:\n",
    "    print('Index does not exist. No need to delete it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1699873172892
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " products created\n"
     ]
    }
   ],
   "source": [
    "# Create a search index\n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"name\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"tagline\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"description\", type=SearchFieldDataType.String),\n",
    "    SimpleField(name=\"original_price\", type=SearchFieldDataType.Double),\n",
    "    SimpleField(name=\"special_offer\", type=SearchFieldDataType.Double),\n",
    "    SearchableField(name=\"category\", type=SearchFieldDataType.String, filterable=True),\n",
    "    SearchField(name=\"tagline_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "    SearchField(name=\"description_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "    SimpleField(name=\"product_image_file\", type=SearchFieldDataType.String),\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    algorithm_configurations=[\n",
    "        VectorSearchAlgorithmConfiguration(\n",
    "            name=\"my-vector-config\",\n",
    "            kind=\"hnsw\",\n",
    "            hnsw_parameters={\n",
    "                \"m\": 4,\n",
    "                \"efConstruction\": 400,\n",
    "                \"efSearch\": 500,\n",
    "                \"metric\": \"cosine\"\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"tagline\"),\n",
    "        prioritized_keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"description\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_settings=semantic_settings)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "gather": {
     "logged": 1699873173454
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 21 documents\n"
     ]
    }
   ],
   "source": [
    "# Upload documents to the index\n",
    "with open(\"./data/product-catalog-vectors.json\", 'r') as file:  \n",
    "    documents = json.load(file)  \n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "result = search_client.upload_documents(documents)  \n",
    "print(f\"Uploaded {len(documents)} documents\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Perform Test Queries\n",
    "We are performing a few test queries against the Cognitive Search index. If successful, it should display outdoor product information and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "gather": {
     "logged": 1699873173581
    }
   },
   "outputs": [],
   "source": [
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)  \n",
    "fields_of_interest = [\"id\", \"name\", \"tagline\", \"description\", \"original_price\", \"special_offer\", \"category\", \"product_image_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1699873175487
    }
   },
   "outputs": [],
   "source": [
    "# Test code for using BlobServiceClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import requests\n",
    "\n",
    "def display_image_from_blob(image_file):\n",
    "    # Append the image name to the SAS URL\n",
    "    image_url = blob_sas_url.split(\"?\")[0] + f\"/{image_file}?\" + blob_sas_url.split(\"?\")[1]\n",
    "    \n",
    "    # Get the image content\n",
    "    response = requests.get(image_url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Open the image and display it\n",
    "        img = plt.imread(BytesIO(response.content))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off') # No axes for this plot\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Failed to retrieve image. HTTP Status code: {response.status_code}\")\n",
    "\n",
    "def print_results(results):  \n",
    "  for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Name: {result['name']}\")  \n",
    "    print(f\"Category: {result['category']}\")\n",
    "    print(f\"Tagline: {result['tagline']}\")\n",
    "    print(f\"Description: {result['description'][:50]}\")\n",
    "    print(f\"Original price: {result['original_price']}\")\n",
    "    print(f\"Special offer: {result['special_offer']}\")\n",
    "    print(f\"Image file: {result['product_image_file']}\\n\")\n",
    "    display_image_from_blob(result['product_image_file'])\n",
    "\n",
    "\n",
    "# Pure Vector Search with Filter\n",
    "# query = \"tent for two people\"\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector=generate_embeddings(query), top_k=3,  \n",
    "    vector_fields=\"description_vector\",\n",
    "    filter=\"category eq 'outdoor'\",\n",
    "    select= fields_of_interest\n",
    ")  \n",
    "  \n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from matplotlib import pyplot as plt\n",
    "from io import BytesIO\n",
    "\n",
    "def display_image_from_blob(image_file):\n",
    "   \n",
    "  # Append the image name to the SAS URL\n",
    "  image_url = blob_sas_url.split(\"?\")[0] + f\"/{image_file}?\" + blob_sas_url.split(\"?\")[1]\n",
    "\n",
    "  # Get the image content\n",
    "  response = requests.get(image_url)\n",
    "\n",
    "  # Check if the request was successful\n",
    "  if response.status_code == 200:\n",
    "      # Open the image and display it\n",
    "      img = plt.imread(BytesIO(response.content))\n",
    "      plt.imshow(img)\n",
    "      plt.axis('off') # No axes for this plot\n",
    "      plt.show()\n",
    "  else:\n",
    "      print(f\"Failed to retrieve image. HTTP Status code: {response.status_code}\")\n",
    "\n",
    "def print_results(results):  \n",
    "  for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Name: {result['name']}\")  \n",
    "    print(f\"Category: {result['category']}\")\n",
    "    print(f\"Tagline: {result['tagline']}\")\n",
    "    print(f\"Description: {result['description'][:50]}\")\n",
    "    print(f\"Original price: {result['original_price']}\")\n",
    "    print(f\"Special offer: {result['special_offer']}\")\n",
    "    print(f\"Image file: {result['product_image_file']}\\n\")\n",
    "    display_image_from_blob(result['product_image_file'])\n",
    "\n",
    "\n",
    "# Pure Vector Search with Filter\n",
    "query = \"tent for two people\"  \n",
    " \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector=generate_embeddings(query), top_k=3,  \n",
    "    vector_fields=\"description_vector\",\n",
    "    filter=\"category eq 'outdoor'\",\n",
    "    select= fields_of_interest\n",
    ")  \n",
    "  \n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure SQL Database\n",
    "Now we are creating a small Azure SQL Database with customer, products and order data using the SQL Server that you have deployed manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Need to modify code to use Entra ID authentication for Azure SQL Database\n",
    "# Ref: https://learn.microsoft.com/zh-tw/azure/azure-sql/database/azure-sql-python-quickstart?view=azuresql&tabs=windows%2Csql-inter\n",
    "\n",
    "import pyodbc\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Azure SQL Database\n",
    "sql_db_server = data[\"Values\"][\"SQL_DB_SERVER\"]\n",
    "sql_db_user = data[\"Values\"][\"SQL_DB_USER\"]\n",
    "sql_db_password = data[\"Values\"][\"SQL_DB_PASSWORD\"]\n",
    "sql_db_name = data[\"Values\"][\"SQL_DB_NAME\"]\n",
    "\n",
    "# Azure SQL Database details\n",
    "sql_db_server = \"your_sql_server.database.windows.net\"\n",
    "sql_db_name = \"your_database_name\"\n",
    "\n",
    "# Get a token credential for Entra ID authentication\n",
    "credential = DefaultAzureCredential()\n",
    "token = credential.get_token(\"https://database.windows.net/.default\")\n",
    "\n",
    "# Connection string using Entra ID authentication\n",
    "server_connection_string = f\"Driver={{ODBC Driver 18 for SQL Server}};Server=tcp:{sql_db_server},1433;Database={sql_db_name};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;Authentication=ActiveDirectoryAccessToken;\"\n",
    "\n",
    "# Test connection to the SQL Server\n",
    "try:\n",
    "    # Try to establish a connection\n",
    "    conn = pyodbc.connect(server_connection_string, attrs_before={1256: token.token})\n",
    "    \n",
    "    # If connection is successful, print a message and close the connection\n",
    "    print(\"Connection to the server/database was successful!\")\n",
    "    conn.close()\n",
    "    \n",
    "except pyodbc.Error as ex:\n",
    "    # Catch any connection errors and print them\n",
    "    sqlstate = ex.args[0] if len(ex.args) > 0 else None\n",
    "    message = ex.args[1] if len(ex.args) > 1 else None\n",
    "    print(f\"Failed to connect to the server/database. SQLSTATE: {sqlstate}, Message: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1699873175635
    }
   },
   "outputs": [],
   "source": [
    "# Connection Strings\n",
    "server_connection_string = f\"Driver={{ODBC Driver 18 for SQL Server}};Server=tcp:{sql_db_server},1433;Uid={sql_db_user};Pwd={sql_db_password};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
    "database_connection_string = server_connection_string + f\"Database={sql_db_name};\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "gather": {
     "logged": 1699873175773
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "customers = [\n",
    "    {\"name\": \"John Doe\", \"account_id\": 1000, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Jane Smith\", \"account_id\": 1001, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Alice Johnson\", \"account_id\": 1002, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Bob Wilson\", \"account_id\": 1003, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Charlie Brown\", \"account_id\": 1004, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Eve Adams\", \"account_id\": 1005, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Frank Castle\", \"account_id\": 1006, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Grace Lee\", \"account_id\": 1007, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Hannah Montan\", \"account_id\": 1008, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Ian Somerhalder\", \"account_id\": 1009, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Peter Mick\", \"account_id\": 1010, \"loyalty_points\" : random.randint(400, 800)},\n",
    "]\n",
    "\n",
    "products = [\n",
    "    {\"id\": 1000, \"name\": \"Elysian Voyager\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1001, \"name\": \"Terra Roamer\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1002, \"name\": \"Cardinal Pathfinder\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1003, \"name\": \"Slumber Drifter\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1004, \"name\": \"Blaze Adventurer\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1005, \"name\": \"BiteShield Pro\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1006, \"name\": \"Feast Frontier\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1007, \"name\": \"Summit Stride\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1008, \"name\": \"Rugged Ranger\",\"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1100, \"name\": \"Match Master\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1101, \"name\": \"Court Queen\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1102, \"name\": \"Junior Ace\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1103, \"name\": \"ServeMaster Pro\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1104, \"name\": \"Court Commander\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1105, \"name\": \"StringMaster Elite\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1106, \"name\": \"Court Conqueror\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1107, \"name\": \"AceMaster 3000\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1108, \"name\": \"Ace Attire\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1109, \"name\": \"Serve & Style\", \"stock\": random.randint(0,50)},\n",
    "]\n",
    "orders = [\n",
    "    {\"order_id\": 1000, \"product_id\": 1001, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1000},\n",
    "    {\"order_id\": 1001, \"product_id\": 1001, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1001},\n",
    "    {\"order_id\": 1002, \"product_id\": 1002, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1002},\n",
    "    {\"order_id\": 1003, \"product_id\": 1003, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1003},\n",
    "    {\"order_id\": 1004, \"product_id\": 1004, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1004},\n",
    "    {\"order_id\": 1005, \"product_id\": 1005, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1005},\n",
    "    {\"order_id\": 1006, \"product_id\": 1006, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1006},\n",
    "    {\"order_id\": 1007, \"product_id\": 1007, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1007},\n",
    "    {\"order_id\": 1008, \"product_id\": 1008, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1008},\n",
    "    {\"order_id\": 1010, \"product_id\": 1000, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1009},\n",
    "    {\"order_id\": 1012, \"product_id\": 1101, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1001},\n",
    "    {\"order_id\": 1013, \"product_id\": 1102, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1002},\n",
    "    {\"order_id\": 1014, \"product_id\": 1103, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1003},\n",
    "    {\"order_id\": 1015, \"product_id\": 1104, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1004},\n",
    "    {\"order_id\": 1016, \"product_id\": 1105, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1005},\n",
    "    {\"order_id\": 1017, \"product_id\": 1106, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1006},\n",
    "    {\"order_id\": 1018, \"product_id\": 1107, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1007},\n",
    "    {\"order_id\": 1019, \"product_id\": 1108, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1008},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1699873175920
    }
   },
   "outputs": [],
   "source": [
    "# Test connection to the SQL Server\n",
    "\n",
    "try:\n",
    "    # Try to establish a connection\n",
    "    conn = pyodbc.connect(server_connection_string)\n",
    "    \n",
    "    # If connection is successful, print a message and close the connection\n",
    "    print(\"Connection to the server/database was successful!\")\n",
    "    conn.close()\n",
    "    \n",
    "except pyodbc.Error as ex:\n",
    "    # Catch any connection errors and print them\n",
    "    sqlstate = ex.args[0] if len(ex.args) > 0 else None\n",
    "    message = ex.args[1] if len(ex.args) > 1 else None\n",
    "    print(f\"Failed to connect to the server/database. SQLSTATE: {sqlstate}, Message: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1699873247080
    }
   },
   "outputs": [],
   "source": [
    "# SET TO TRUE ONLY TO REBUILD DATABASE BASED ON ABOVE SAMPLE DATA\n",
    "rebuild_database = True\n",
    "\n",
    "if rebuild_database:\n",
    "\n",
    "    # Connect to the server without specifying a database\n",
    "    server_conn = pyodbc.connect(server_connection_string, autocommit=True)\n",
    "    server_cursor = server_conn.cursor()\n",
    "\n",
    "    # Drop the database if it exists\n",
    "    server_cursor.execute(f\"IF EXISTS(SELECT * FROM sys.databases WHERE name='{sql_db_name}') DROP DATABASE [{sql_db_name}]\")\n",
    "\n",
    "    # Recreate the database\n",
    "    server_cursor.execute(f\"CREATE DATABASE [{sql_db_name}]\")\n",
    "    server_cursor.close()\n",
    "    server_conn.close()\n",
    "\n",
    "    # Now, connect to the newly created database\n",
    "    conn = pyodbc.connect(database_connection_string)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Ensure you're using the existing database\n",
    "    cursor.execute(f\"USE [{sql_db_name}]\")\n",
    "\n",
    "    # Create tables and populate them\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE Customers (\n",
    "        name VARCHAR(255),\n",
    "        account_id INT PRIMARY KEY,\n",
    "        loyalty_points INT,\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    for customer in customers:\n",
    "        cursor.execute(\"INSERT INTO Customers VALUES (?, ?, ?)\", \n",
    "                    (customer[\"name\"], customer[\"account_id\"], customer[\"loyalty_points\"]))\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE Products (\n",
    "        id INT PRIMARY KEY,\n",
    "        name VARCHAR(255),\n",
    "        stock INT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    for product in products:\n",
    "        cursor.execute(\"INSERT INTO Products VALUES (?, ?, ?)\", \n",
    "                    (product[\"id\"], product[\"name\"], product[\"stock\"]))\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE Orders (\n",
    "        order_id INT PRIMARY KEY,\n",
    "        product_id INT,\n",
    "        days_to_delivery INT,\n",
    "        account_id INT,\n",
    "        FOREIGN KEY(product_id) REFERENCES Products(id),\n",
    "        FOREIGN KEY(account_id) REFERENCES Customers(account_id)\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    for order in orders:\n",
    "        cursor.execute(\"INSERT INTO Orders VALUES (?, ?, ?, ?)\", \n",
    "                    (order[\"order_id\"], order[\"product_id\"], order[\"days_to_delivery\"], order[\"account_id\"]))\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    #Verify database tables and columns\n",
    "    def fetch_schema_info():\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT t.TABLE_NAME, c.COLUMN_NAME, c.DATA_TYPE \n",
    "            FROM INFORMATION_SCHEMA.TABLES AS t\n",
    "            JOIN INFORMATION_SCHEMA.COLUMNS AS c ON t.TABLE_NAME = c.TABLE_NAME\n",
    "            WHERE t.TABLE_SCHEMA = 'dbo'  -- assuming you're using the default schema\n",
    "            ORDER BY t.TABLE_NAME, c.ORDINAL_POSITION\n",
    "        \"\"\")\n",
    "        \n",
    "        tables = {}\n",
    "        for row in cursor.fetchall():\n",
    "            table_name = row[0]\n",
    "            column_name = row[1]\n",
    "            data_type = row[2]\n",
    "            \n",
    "            if table_name not in tables:\n",
    "                tables[table_name] = []\n",
    "            \n",
    "            tables[table_name].append(f\"{column_name} ({data_type})\")\n",
    "        \n",
    "        return tables\n",
    "\n",
    "    schema_info = fetch_schema_info()\n",
    "\n",
    "    # Print the schema info in a user-friendly format\n",
    "    for table, columns in schema_info.items():\n",
    "        print(f\"Table: {table}\")\n",
    "        for col in columns:\n",
    "            print(f\"    {col}\")\n",
    "        print()\n",
    "\n",
    "    # Close connections\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
